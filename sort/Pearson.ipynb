{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import csv\n",
    "from random import randrange\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import float32\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply(a,b):\n",
    "    sum_ab=0.0\n",
    "    for i in range(len(a)):\n",
    "        temp=a[i]*b[i]\n",
    "        sum_ab+=temp\n",
    "    return sum_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_pearson(x,y):\n",
    "    n=len(x)\n",
    "    sum_x=sum(x)\n",
    "    sum_y=sum(y)\n",
    "    sum_xy=multiply(x,y)\n",
    "    sum_x2 = sum([pow(i,2) for i in x])\n",
    "    sum_y2 = sum([pow(j,2) for j in y])\n",
    "    molecular=sum_xy-(float(sum_x)*float(sum_y)/n)\n",
    "    denominator=sqrt((sum_x2-float(sum_x**2)/n)*(sum_y2-float(sum_y**2)/n))\n",
    "    return molecular/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_ranking(pearson):\n",
    "    idx = np.argsort(pearson)  \n",
    "    return idx[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_list =list()\n",
    "\n",
    "def main():\n",
    "    expression=np.loadtxt('初筛后的基因shu.csv',delimiter=',')\n",
    "    X=np.array(expression[:,:-1],dtype=float32)\n",
    "    y=np.array(expression[:,-1], dtype=int)\n",
    "    n_samples, n_features = X.shape    # number of samples and number of features\n",
    "    kf =KFold(n_splits=10)\n",
    "    \n",
    "    feature_number_list =list(range(5,21,1))+list(range(30,101,10))\n",
    "    \n",
    "    for feature_number in feature_number_list:\n",
    "        clf = RandomForestClassifier(n_estimators=200,max_features='sqrt', oob_score=True,random_state=120) \n",
    "        #clf = xgb.XGBClassifier(objective= 'multi:softmax',num_class=6,nthread=4,seed=10,eval_metric='merror')\n",
    "        #clf = LogisticRegression(multi_class=\"multinomial\",solver=\"newton-cg\")   \n",
    "        correct = 0\n",
    "        for train, test in kf.split(X):\n",
    "            pearson =list()\n",
    "            for i in range(n_features):\n",
    "                pearson.append(cal_pearson(X[train,i],y[train]))\n",
    "            idx = feature_ranking(pearson)  \n",
    "            selected_features = X[:, idx[0:feature_number]] \n",
    "            clf.fit(selected_features[train], y[train])  # train a classification model with the selected features on the training dataset\n",
    "            y_predict = clf.predict(selected_features[test])\n",
    "            acc = accuracy_score(y[test], y_predict)\n",
    "            correct = correct + acc\n",
    "        acc_list.append(float(correct)/10)\n",
    "        print('Accuracy:{:6f}'.format(float(correct)/10))\n",
    "    return acc_list\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
